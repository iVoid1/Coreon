# ğŸ§  BitVoid â€” Personal Voice Assistant (Prototype)

BitVoid is a personal AI-driven voice assistant prototype designed to simulate real-time conversations with a local Large Language Model (LLM) using voice input and output.

## ğŸ¯ Current Progress

- [X]  ğŸ™ï¸ Speech-to-Text (STT) implemented using [Vosk] for accurate offline speech recognition.
- [X]  ğŸ—£ï¸ Text-to-Speech (TTS) functionality implemented leveraging [Edge-TTS] for natural voice output.
- [X]  ğŸ¤– Local LLM Integration through [Ollama] running models like LLaMA 3.1 on your local machine.
- [X]  ğŸ”„ Basic asynchronous interactive loop prototype connecting speech input, AI processing, and voice output.
- [X]  ğŸ—‚ï¸ Organized project structure with modular design separating core logic, I/O methods, memory management, and model interface.
- [ ]  ğŸ§  Simple memory manager implemented for storing and retrieving conversational context.
- [ ]  ğŸ’¾ Automatic message logging with timestamps (planned).
- [ ]  ğŸ§© Advanced personalization and dynamic learning modules (planned).
- [ ]  ğŸ”§ Robust error handling and full async concurrency enhancements (planned).
- [ ]  ğŸ“¦ Dependencies

Install required packages:

### `pip install -r requirements.txt`

---

## âš ï¸ Required Model Download (at lease for now)

This project uses the Vosk speech recognition model, which is not included in the repository due to its large size.
ğŸ“¥ How to Set Up the Model

1. Download an English model from the official Vosk website: [Vosk](

- âœ… Recommended for high accuracy: vosk-model-en-us-0.22
- ğŸŸ¢ Smaller and faster: vosk-model-small-en-us-0.15

2. Extract the downloaded model into your project directory.
3. Open the config.json file in config folder and update the `vosk_model` field to match the folder name:

```json
{
    "vosk_model": "assets/vosk-model-en-us-0.22", <-- that's what you need to update
    "sample_rate": 16000,
    "chunk": 8000,
    "log_file": "",
    "ollama_model": "llama3.1",
    "ollama_url": "http://localhost:11434",
    "ollama_post": "http://localhost:11434/api/chat"
}
```

## ğŸ—‚ï¸ Project Structure Overview

```
BitVoid/

â”œâ”€â”€bitvoid/
| |
| â”œâ”€â”€ core/
| â”‚   â”œâ”€â”€ bitvoid.py          # Main assistant logic orchestrator (BitVoid class)
| â”‚   â”œâ”€â”€ memory_manager.py   # Memory module for storing conversation context
| â”‚   â””â”€â”€ ollama_model.py     # Interface to local LLM via Ollama
| â”‚
| â”œâ”€â”€ config/
| â”‚   â”œâ”€â”€ config.json         # External configuration file (paths, audio settings)
| â”‚   â””â”€â”€ Config.py           # Reads config.json and exposes usable config values
| â”‚
| â”œâ”€â”€ io_methods/
| â”‚   â”œâ”€â”€ stt.py              # Speech-to-Text using Vosk
| â”‚   â”œâ”€â”€ tts.py              # Text-to-Speech using Edge-TTS
| â”‚   â””â”€â”€ chat.py             # Conversation Flow Controller (planned)
| â”‚
| â”œâ”€â”€ utils/
| â”‚   â””â”€â”€ logger.py           # Logging utilities (planned)
| â”‚
| â””â”€â”€data/
|    â””â”€â”€ memory.json         # Persistent long-term memory file
â”œâ”€â”€ tests/
|
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirement.txt
â””â”€â”€ main.py                 # App entry point â€” initializes and runs BitVoid

```

## ğŸš€ Next Steps

- [ ] Complete implementation of the interactive conversation loop with real-time speech streaming.
- [ ] Develop dynamic memory and personalization to enable context-aware dialogue.
- [ ] Add automatic timestamped logging for debugging and conversation history.
- [ ] Expand language support with translation layers (e.g., Whisper).
- [ ] Refine error handling and concurrency for smoother user experience.
